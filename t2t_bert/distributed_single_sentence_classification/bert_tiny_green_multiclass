config_file=./BERT/data/roberta_zh_l12/bert_config_tiny.json
init_checkpoint=bert_pretrain/open_domain/pretrained_model/roberta/roberta_tiny_312/model.ckpt-1145800
vocab_file=./BERT/data/chinese_L-12_H-768_A-12/vocab.txt
label_id=./BERT/data/green/label_dict.json
max_length=256
train_file="bert_pretrain/open_domain/pretrain_single_random_green_gan/finetuning/dataset/green_finetuning_train_multilabel.tfrecord_0,bert_pretrain/open_domain/pretrain_single_random_green_gan/finetuning/dataset/green_finetuning_train_multilabel.tfrecord_1,bert_pretrain/open_domain/pretrain_single_random_green_gan/finetuning/dataset/green_finetuning_train_multilabel.tfrecord_2,bert_pretrain/open_domain/pretrain_single_random_green_gan/finetuning/dataset/green_finetuning_train_multilabel.tfrecord_3,bert_pretrain/open_domain/pretrain_single_random_green_gan/finetuning/dataset/green_finetuning_train_multilabel.tfrecord_4,bert_pretrain/open_domain/pretrain_single_random_green_gan/finetuning/dataset/green_finetuning_train_multilabel.tfrecord_5,bert_pretrain/open_domain/pretrain_single_random_green_gan/finetuning/dataset/green_finetuning_train_multilabel.tfrecord_6,bert_pretrain/open_domain/pretrain_single_random_green_gan/finetuning/dataset/green_finetuning_train_multilabel.tfrecord_7,bert_pretrain/open_domain/pretrain_single_random_green_gan/finetuning/dataset/green_finetuning_train_multilabel.tfrecord_8,bert_pretrain/open_domain/pretrain_single_random_green_gan/finetuning/dataset/green_finetuning_train_multilabel.tfrecord_9,bert_pretrain/open_domain/pretrain_single_random_green_gan/finetuning/dataset/green_finetuning_train_multilabel.tfrecord_10,bert_pretrain/open_domain/pretrain_single_random_green_gan/finetuning/dataset/green_finetuning_train_multilabel.tfrecord_11,bert_pretrain/open_domain/pretrain_single_random_green_gan/finetuning/dataset/green_finetuning_train_multilabel.tfrecord_12,bert_pretrain/open_domain/pretrain_single_random_green_gan/finetuning/dataset/green_finetuning_train_multilabel.tfrecord_13,bert_pretrain/open_domain/pretrain_single_random_green_gan/finetuning/dataset/green_finetuning_train_multilabel.tfrecord_14"
dev_file=bert_pretrain/open_domain/pretrain_single_random_green_gan/finetuning/green_finetuning_eval_multilabel.tfrecord
model_output=bert_pretrain/open_domain/pretrain_single_random_green_gan/finetuning/roberta_tiny_multilabel_circle_loss_v1
epoch=10
label_type='multi_label'
loss='circle_loss'
num_classes=15
train_size=550000
eval_size=90000
batch_size=48
model_type=bert
if_shard=2
is_debug=1
run_type=estimator
opt_type="all_reduce"
num_gpus=4
parse_type=parse_batch_multi_task
rule_model=normal
profiler="no"
train_op=adam_weight_decay_exclude
running_type=train
cross_tower_ops_type=paisoar
distribution_strategy=MirroredStrategy
load_pretrained=yes
warmup=warmup
decay=decay
with_target=""
input_target=""
distillation="normal"
temperature=2.0
distillation_ratio=1.0
num_hidden_layers=12
task_type=single_sentence_multilabel_classification
classifier=order_classifier
mode="single_task"
multi_task_type="wsdm,ccks,ant,xnli,lcqmc,chnsenticorp"
multi_task_config="./BERT/t2t_bert/distributed_multitask/multi_task.json"
task_invariant=no
init_lr=1e-4
data_prior='0.066,0.066,0.066,0.066,0.066,0.066,0.066,0.066,0.066,0.066,0.066,0.066,0.066,0.066,0.066'
